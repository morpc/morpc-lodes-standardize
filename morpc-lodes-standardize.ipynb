{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81791ad-8f58-4124-bba3-f857c73262b3",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317fdc10-a19b-4e68-befc-08a712f7ee28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b8908-2b9f-4931-b6b3-9ecd24d118eb",
   "metadata": {},
   "source": [
    "This process is dependent on upstream processes. See the \"Prerequisites\" section below.\n",
    "\n",
    "The workflow defined herein is identified as workflow ID #TBD in the [Data Team Master Document List](https://morpc1.sharepoint.com/:x:/s/GISteam/EfC4j3HhohZCrSZzxJdyt5cBFEqVD7zHick8ZW0INqgCYA?e=0WhrAI). References to document list identifiers are denoted by a number in brackets, e.g. [TBD]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05b048-045c-402d-bb52-708110691f09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c214d-69e7-4112-b7bb-3e9d377a594e",
   "metadata": {},
   "source": [
    "## Prerequisites and usage notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e9d1d-aa32-4ec2-a42e-5c44e39c694f",
   "metadata": {},
   "source": [
    "  - Outputs of one or more upstream workflows must be available at the indicated paths. Make sure that those outputs are up to date prior to running this script. \n",
    "  - This script includes several intentional RuntimeError instances that may be triggered to alert the user to conditions that may require their attention. If the script triggers one of these errors, review the error, verify that the condition is acceptable or resolve any issues, then proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ee0c6-4158-4a98-bc7f-179022f48ff8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd65147-7804-4778-8def-493d8f2f3542",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4dabf2d-e5d6-4e5b-8b1a-160bbfd32420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import morpc\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"./main\")\n",
    "import download_and_unzip\n",
    "import build_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed7156-7d69-400e-92e8-be275d318067",
   "metadata": {},
   "source": [
    "### User-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c907f2-fcdc-4f84-b8c5-22097daf822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When STALE_DATA_INTERRUPT == True, the script will produce a RuntimeError in certain situations where the input \n",
    "# data may be stale and updates might be required prior to running the script.  Otherwise, a warning will be generated \n",
    "# but script execution will continue.  Regardless of whether an error or warning occurs, be sure to verify the readiness \n",
    "# of all input data.\n",
    "STALE_DATA_INTERRUPT = True\n",
    "\n",
    "# This script may pull data from outputs of upstream workflows.  The locations of these outputs are specified by their path relative\n",
    "# a GitHub root directory. This is a single directory which is presumed to contain local working copies of MORPC GitHub repositories.\n",
    "# Specify the path to the directory on your system where the local working copies are stored. By default, the GitHub root directory is\n",
    "# assumed to be one level up from this script.\n",
    "GITHUB_ROOT = \"../\"\n",
    "\n",
    "# Specify the path to the directory where the input data is stored. Sometimes the data may be sourced from this location and sometimes \n",
    "# it may be sourced from elsewhere and archived here.\n",
    "INPUT_DIR = \"./input_data\"\n",
    "\n",
    "# Specify the path to the directory where the output data is stored. Typically it is not necessary to change this, and changing it for \n",
    "# established scripts may break other scripts that depend on outputs from this one.\n",
    "OUTPUT_DIR = \"./output_data\"\n",
    "\n",
    "# Specify the path to the directory where temporary outputs are stored.  Typically this is used to capture data or artifacts that are useful\n",
    "# for understanding the internal workings of a script but which are not considered to be official outputs of the script and may not be \n",
    "# acceptable for use in downstream workflows.\n",
    "TEMP_DIR = \"./temp_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c0fde-7773-4ffc-b47c-f1b40f283def",
   "metadata": {},
   "source": [
    "### Static parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0004e0a-e241-4757-b5bd-c9819d943514",
   "metadata": {},
   "source": [
    "### Define inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab663116-d72d-4f63-8b4c-ba40212d3715",
   "metadata": {},
   "source": [
    "The following datasets are required by this notebook. They will be retrieved from the specified location and temporarily stored in INPUT_DIR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da01ea-fc9e-41d2-b715-11fa170c2ca4",
   "metadata": {},
   "source": [
    "#### Create input data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ae4d6-e9a3-495e-a339-b7bc598b0926",
   "metadata": {},
   "source": [
    "Create input data directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c03840-4cb0-4417-b97e-2b21b1363f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir = os.path.normpath(INPUT_DIR)\n",
    "if not os.path.exists(inputDir):\n",
    "    os.makedirs(inputDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac8737d-5330-40d1-8b06-253918294f23",
   "metadata": {},
   "source": [
    "#### MORPC counties reference data [81]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbb81a-e893-4ed3-a42e-6cc6b2535f3e",
   "metadata": {},
   "source": [
    "Reference data for counties in the MORPC region will be loaded automatically as a morpc.countyLookup() object (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89988c-dce5-4ce3-955b-f608c7fe6c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example input dataset [TBD]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8d923c2-36ec-4b09-b78d-9b4f2e0bbbfa",
   "metadata": {},
   "source": [
    "# NOTE: As a best practice that the input schema should not be written by the script.  Rather, it should be created separately \n",
    "# (optionally with help from frictionless.Schema.describe) and only read by the script.  This will ensure that an error is produced during\n",
    "# validation if the schema of the output data is inadvertently changed.\n",
    "INPUT_FILENAME = \"foo.csv\"\n",
    "INPUT_PATH = os.path.join(GITHUB_ROOT, \"some-github-repo/output_data/{}\".format(INPUT_FILENAME))   # Assumes that input is pulled from output of an upstream workflow\n",
    "INPUT_SCHEMA_PATH = INPUT_PATH.replace(\".csv\",\".schema.yaml\")\n",
    "INPUT_RESOURCE_PATH = INPUT_PATH.replace(\".csv\",\".resource.yaml\")\n",
    "print(\"Data: {}\".format(INPUT_PATH))\n",
    "print(\"Schema: {}\".format(INPUT_SCHEMA_PATH))\n",
    "print(\"Resource: {}\".format(INPUT_RESOURCE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406c4a9-051c-4f0c-8148-504019f37f72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9356099-b192-4921-9822-8db1cdc42eda",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create output data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892dc452-34c3-4d08-96ab-be3857d36033",
   "metadata": {},
   "source": [
    "Create output data directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079addf5-cb85-41a2-afa9-6eb226be1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = os.path.normpath(OUTPUT_DIR)\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3079f3-8c93-401e-b40d-5c4e13d86ede",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create temporary data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd9d74-db09-4e68-a2c6-aea6b4f870be",
   "metadata": {},
   "source": [
    "Create temporary data directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbfb4de-852b-4aa6-81ba-5d416458fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDir = os.path.normpath(TEMP_DIR)\n",
    "if not os.path.exists(tempDir):\n",
    "    os.makedirs(tempDir)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690229f-e030-4816-90b3-2ab29e7cd4c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example output dataset [TBD]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e84227eb-95ff-4c93-8497-3f7bdb420926",
   "metadata": {},
   "source": [
    "OUTPUT_FILENAME = \"foo.csv\"\n",
    "OUTPUT_PATH = os.path.join(outputDir, OUTPUT_FILENAME)\n",
    "OUTPUT_SCHEMA_PATH = OUTPUT_PATH.replace(\".csv\",\".schema.yaml\")\n",
    "OUTPUT_RESOURCE_PATH = OUTPUT_PATH.replace(\".csv\",\".resource.yaml\")\n",
    "print(\"Data: {}\".format(OUTPUT_PATH))\n",
    "print(\"Schema: {}\".format(OUTPUT_SCHEMA_PATH))\n",
    "print(\"Resource: {}\".format(OUTPUT_RESOURCE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eedadf-8229-49e7-b553-b2eb396a70e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fd177-fd39-47e6-8290-fc4a72fd4cbc",
   "metadata": {},
   "source": [
    "### Load county reference data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3082e588-4faf-4165-bbf0-6a439641ff03",
   "metadata": {},
   "source": [
    "countyLookup = morpc.countyLookup(scope=\"15-County Region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d9d0a-ef9a-49c3-8d04-14a9a72592f3",
   "metadata": {},
   "source": [
    "### Load example input data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4b56867-f77c-4a84-9706-004c21657e56",
   "metadata": {},
   "source": [
    "(inputData, inputResource, inputSchema) = morpc.frictionless.load_data(INPUT_RESOURCE_PATH, archiveDir=inputDir, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f3f69-4f4b-4e73-b786-523eb711e0a4",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd848e0-46a7-44c2-82ea-ef1f21a302e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DB_PATH = os.path.join(outputDir, \"morpc-lodes-standardize.db\")\n",
    "FILELIST_FILENAME = \"lodesFiles\"\n",
    "FILELIST_PATH = os.path.join(tempDir, \"{}.pkl\".format(FILELIST_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaef3786-0cb9-48bf-a770-cf5aa188a857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing file list at temp_data\\lodesFiles.pkl\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists(FILELIST_PATH)):\n",
    "    print(\"Using existing file list at {}\".format(FILELIST_PATH))\n",
    "    with open(FILELIST_PATH, \"rb\") as f:\n",
    "           lodesFiles = pickle.load(f)\n",
    "else:\n",
    "    print(\"Scraping file list from BLS website.\")\n",
    "    lodesFiles = download_and_unzip.get_all_possible_files(save=True, savepath=tempDir, savename=FILELIST_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a8ca3c7-3a39-4bd8-a014-92f01d6b6a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 23:19:08\n",
      "oh + od...\n",
      "downloading 220 od files\n",
      "0.5% complete...\n",
      "23.2% complete...\n",
      "Skipped 50 files that already existed\n",
      "45.9% complete...\n",
      "Skipped 100 files that already existed\n",
      "68.6% complete...\n",
      "Skipped 150 files that already existed\n",
      "91.4% complete...\n",
      "Skipped 200 files that already existed\n",
      "100.0% complete...\n",
      "Skipped 219 files that already existed\n",
      "oh + rac...\n",
      "downloading 1098 rac files\n",
      "0.1% complete...\n",
      "Skipped 220 files that already existed\n",
      "4.6% complete...\n",
      "Skipped 270 files that already existed\n",
      "9.2% complete...\n",
      "Skipped 320 files that already existed\n",
      "13.8% complete...\n",
      "Skipped 370 files that already existed\n",
      "18.3% complete...\n",
      "Skipped 420 files that already existed\n",
      "22.9% complete...\n",
      "Skipped 470 files that already existed\n",
      "27.4% complete...\n",
      "Skipped 520 files that already existed\n",
      "32.0% complete...\n",
      "Skipped 570 files that already existed\n",
      "36.5% complete...\n",
      "Skipped 620 files that already existed\n",
      "41.1% complete...\n",
      "Skipped 670 files that already existed\n",
      "45.6% complete...\n",
      "Skipped 720 files that already existed\n",
      "50.2% complete...\n",
      "Skipped 770 files that already existed\n",
      "54.7% complete...\n",
      "Skipped 820 files that already existed\n",
      "59.3% complete...\n",
      "Skipped 870 files that already existed\n",
      "63.8% complete...\n",
      "Skipped 920 files that already existed\n",
      "68.4% complete...\n",
      "Skipped 970 files that already existed\n",
      "73.0% complete...\n",
      "Skipped 999 files that already existed\n",
      "77.5% complete...\n",
      "Skipped 999 files that already existed\n",
      "82.1% complete...\n",
      "Skipped 999 files that already existed\n",
      "86.6% complete...\n",
      "Skipped 999 files that already existed\n",
      "91.2% complete...\n",
      "Skipped 999 files that already existed\n",
      "95.7% complete...\n",
      "Skipped 999 files that already existed\n",
      "100.0% complete...\n",
      "Skipped 999 files that already existed\n",
      "oh + wac...\n",
      "downloading 1088 wac files\n",
      "0.1% complete...\n",
      "Skipped 999 files that already existed\n",
      "4.7% complete...\n",
      "Skipped 999 files that already existed\n",
      "9.3% complete...\n",
      "Skipped 999 files that already existed\n",
      "13.9% complete...\n",
      "Skipped 999 files that already existed\n",
      "18.5% complete...\n",
      "Skipped 999 files that already existed\n",
      "23.1% complete...\n",
      "Skipped 999 files that already existed\n",
      "27.7% complete...\n",
      "Skipped 999 files that already existed\n",
      "32.3% complete...\n",
      "Skipped 999 files that already existed\n",
      "36.9% complete...\n",
      "Skipped 999 files that already existed\n",
      "41.5% complete...\n",
      "Skipped 999 files that already existed\n",
      "46.0% complete...\n",
      "Skipped 999 files that already existed\n",
      "50.6% complete...\n",
      "Skipped 999 files that already existed\n",
      "55.2% complete...\n",
      "Skipped 999 files that already existed\n",
      "59.8% complete...\n",
      "Skipped 999 files that already existed\n",
      "64.4% complete...\n",
      "Skipped 999 files that already existed\n",
      "69.0% complete...\n",
      "Skipped 999 files that already existed\n",
      "73.6% complete...\n",
      "Skipped 999 files that already existed\n",
      "78.2% complete...\n",
      "Skipped 999 files that already existed\n",
      "82.8% complete...\n",
      "Skipped 999 files that already existed\n",
      "87.4% complete...\n",
      "Skipped 999 files that already existed\n",
      "92.0% complete...\n",
      "Skipped 999 files that already existed\n",
      "96.6% complete...\n",
      "Skipped 999 files that already existed\n",
      "100.0% complete...\n",
      "Skipped 999 files that already existed\n",
      "oh + cw...\n",
      "downloading 1 cw files\n",
      "100.0% complete...\n",
      "Skipped 999 files that already existed\n",
      "done downloading!\n",
      "Skipped 999 files that already existed\n",
      "end time: 23:43:26\n"
     ]
    }
   ],
   "source": [
    "downloadDir = download_and_unzip.download_state_lodes_file(save_loc=tempDir,\n",
    "                          st='oh',\n",
    "                          links_dict=lodesFiles,\n",
    "                          skip_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7030b52a-277b-4e51-a561-375fbc9337bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadDir = os.path.join(tempDir, \"oh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97189611-b9ee-410a-a4c0-da92cdb3bb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 23:53:57\n",
      "unzipping 1 cw files\n",
      "100.0% complete...\n",
      "unzipping 440 od files\n",
      "0.2% complete...\n",
      "11.6% complete...\n",
      "Skipped 25 files that already existed\n",
      "23.0% complete...\n",
      "Skipped 50 files that already existed\n",
      "34.3% complete...\n",
      "Skipped 75 files that already existed\n",
      "45.7% complete...\n",
      "Skipped 100 files that already existed\n",
      "57.0% complete...\n",
      "Skipped 125 files that already existed\n",
      "68.4% complete...\n",
      "Skipped 150 files that already existed\n",
      "79.8% complete...\n",
      "Skipped 175 files that already existed\n",
      "91.1% complete...\n",
      "Skipped 200 files that already existed\n",
      "100.0% complete...\n",
      "Skipped 219 files that already existed\n",
      "unzipping 1877 rac files\n",
      "0.1% complete...\n",
      "2.7% complete...\n",
      "Skipped 25 files that already existed\n",
      "5.4% complete...\n",
      "Skipped 50 files that already existed\n",
      "8.0% complete...\n",
      "Skipped 75 files that already existed\n",
      "10.7% complete...\n",
      "Skipped 100 files that already existed\n",
      "13.4% complete...\n",
      "Skipped 125 files that already existed\n",
      "16.0% complete...\n",
      "Skipped 150 files that already existed\n",
      "18.7% complete...\n",
      "Skipped 175 files that already existed\n",
      "21.4% complete...\n",
      "Skipped 200 files that already existed\n",
      "24.0% complete...\n",
      "Skipped 225 files that already existed\n",
      "26.7% complete...\n",
      "Skipped 250 files that already existed\n",
      "29.4% complete...\n",
      "Skipped 275 files that already existed\n",
      "32.0% complete...\n",
      "Skipped 300 files that already existed\n",
      "34.7% complete...\n",
      "Skipped 325 files that already existed\n",
      "37.3% complete...\n",
      "Skipped 350 files that already existed\n",
      "40.0% complete...\n",
      "Skipped 375 files that already existed\n",
      "42.7% complete...\n",
      "Skipped 400 files that already existed\n",
      "45.3% complete...\n",
      "Skipped 425 files that already existed\n",
      "48.0% complete...\n",
      "Skipped 450 files that already existed\n",
      "50.7% complete...\n",
      "Skipped 475 files that already existed\n",
      "53.3% complete...\n",
      "Skipped 500 files that already existed\n",
      "56.0% complete...\n",
      "Skipped 525 files that already existed\n",
      "58.7% complete...\n",
      "Skipped 550 files that already existed\n",
      "61.3% complete...\n",
      "Skipped 575 files that already existed\n",
      "64.0% complete...\n",
      "Skipped 600 files that already existed\n",
      "66.6% complete...\n",
      "Skipped 625 files that already existed\n",
      "69.3% complete...\n",
      "Skipped 650 files that already existed\n",
      "72.0% complete...\n",
      "Skipped 675 files that already existed\n",
      "74.6% complete...\n",
      "Skipped 700 files that already existed\n",
      "77.3% complete...\n",
      "Skipped 725 files that already existed\n",
      "80.0% complete...\n",
      "Skipped 750 files that already existed\n",
      "82.6% complete...\n",
      "Skipped 775 files that already existed\n",
      "85.3% complete...\n",
      "Skipped 779 files that already existed\n",
      "88.0% complete...\n",
      "Skipped 779 files that already existed\n",
      "90.6% complete...\n",
      "Skipped 779 files that already existed\n",
      "93.3% complete...\n",
      "Skipped 779 files that already existed\n",
      "96.0% complete...\n",
      "Skipped 779 files that already existed\n",
      "98.6% complete...\n",
      "Skipped 779 files that already existed\n",
      "100.0% complete...\n",
      "Skipped 779 files that already existed\n",
      "unzipping 1088 wac files\n",
      "0.1% complete...\n",
      "4.7% complete...\n",
      "9.3% complete...\n",
      "13.9% complete...\n",
      "18.5% complete...\n",
      "23.1% complete...\n",
      "27.7% complete...\n",
      "32.3% complete...\n",
      "36.9% complete...\n",
      "41.5% complete...\n",
      "46.0% complete...\n",
      "50.6% complete...\n",
      "55.2% complete...\n",
      "59.8% complete...\n",
      "64.4% complete...\n",
      "69.0% complete...\n",
      "73.6% complete...\n",
      "78.2% complete...\n",
      "82.8% complete...\n",
      "87.4% complete...\n",
      "92.0% complete...\n",
      "96.6% complete...\n",
      "100.0% complete...\n",
      "end time: 23:55:28\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip.unzip_state_lodes_file(state_fold=downloadDir, skip_existing=True, delete_corrupt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4d2aa8c-32a1-4dc5-8909-c6f711246781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'build_database' from 'C:\\\\Users\\\\aporr\\\\github\\\\morpc-lodes-standardize\\\\main\\\\build_database.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(build_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a4f68f3-9374-483e-8b73-539463c36b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building sqlite db...\n",
      "could not create sqlite db at: output_data\\morpc-lodes-standardize.db. The specified module could not be found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loads downloaded data into spatialite \n",
    "build_database.build_db(spath=OUTPUT_DB_PATH) #be careful - this build function overwrites existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7dadb-b36e-45c3-a2fd-23cc39c8502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_fold = r\"C:\\Users\\cmg0003\\Desktop\\TX_Lodes_Download\\tx\"\n",
    "load_lodes_into_db(folder_path = state_fold,spath = spath, base_only = True)\n",
    "load_geometries_into_db(spath=spath) #note - this is basically a custom function for texas geometries - will need work for other states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae0d80-e7cf-4ae3-b4ea-79297298bdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72e66244-d106-41c3-8d79-b6f65447f329",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05d91f-7b32-40c5-b07b-ea676174216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputData.to_csv(OUTPUT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05c0f8-5d84-428e-9f21-01fb4b1fb85e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputResource = morpc.frictionless.create_resource(OUTPUT_FILENAME, \n",
    "    resourcePath=OUTPUT_RESOURCE_PATH,\n",
    "    title=\"Enter a meaningful title for the output dataset\", \n",
    "    description=\"Enter a more detailed description of the output dataset.\",\n",
    "    writeResource=True,\n",
    "    validate=True\n",
    ")\n",
    "outputResource"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
